{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import uuid\n",
    "\n",
    "from kafka import KafkaProducer, KafkaAdminClient\n",
    "from kafka.admin.new_topic import NewTopic\n",
    "from kafka.errors import TopicAlreadyExistsError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration Parameters \n",
    "\n",
    "> **TODO:** Change the configuration prameters to the appropriate values for your setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap_servers': ['kafka.kafka.svc.cluster.local:9092'],\n",
       " 'first_name': 'Scott',\n",
       " 'last_name': 'Breitbach',\n",
       " 'client_id': 'BreitbachScott',\n",
       " 'topic_prefix': 'BreitbachScott'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = dict(\n",
    "    bootstrap_servers=['kafka.kafka.svc.cluster.local:9092'],\n",
    "    first_name='Scott',\n",
    "    last_name='Breitbach'\n",
    ")\n",
    "\n",
    "config['client_id'] = '{}{}'.format(\n",
    "    config['last_name'], \n",
    "    config['first_name']\n",
    ")\n",
    "config['topic_prefix'] = '{}{}'.format(\n",
    "    config['last_name'], \n",
    "    config['first_name']\n",
    ")\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Topic Utility Function\n",
    "\n",
    "The `create_kafka_topic` helps create a Kafka topic based on your configuration settings.  For instance, if your first name is *John* and your last name is *Doe*, `create_kafka_topic('locations')` will create a topic with the name `DoeJohn-locations`.  The function will not create the topic if it already exists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pyarrow.parquet as pq\n",
    "from collections import namedtuple\n",
    "# Set path to data\n",
    "src_data_path = '/home/jovyan/dsc650/data/processed/bdd/'\n",
    "\n",
    "# Load acceleration data into pandas dataframe\n",
    "accel_df = pq.ParquetDataset(\n",
    "    src_data_path + 'accelerations/').read_pandas().to_pandas()\n",
    "\n",
    "# Reorder columns\n",
    "accel_cols = [\n",
    "    'offset',\n",
    "    'ride_id',\n",
    "    'uuid', \n",
    "    'timestamp', \n",
    "    'x', 'y', 'z',\n",
    "    'timelapse', \n",
    "    'filename', \n",
    "    't'\n",
    "]\n",
    "\n",
    "# Order df by specified columns & sort by offset value\n",
    "accel_df = accel_df[accel_cols].sort_values(by=['offset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offset</th>\n",
       "      <th>ride_id</th>\n",
       "      <th>uuid</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>timelapse</th>\n",
       "      <th>filename</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.822061</td>\n",
       "      <td>c9a2b46c9aa515b632eddc45c4868482</td>\n",
       "      <td>19b9aa10588646b3bf22c9b4865a7995</td>\n",
       "      <td>1970-01-01 00:25:03.882586</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>0.045</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>False</td>\n",
       "      <td>e2f795a7-6a7d-4500-b5d7-4569de996811.mov</td>\n",
       "      <td>000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     offset                           ride_id  \\\n",
       "0  0.822061  c9a2b46c9aa515b632eddc45c4868482   \n",
       "\n",
       "                               uuid                  timestamp      x      y  \\\n",
       "0  19b9aa10588646b3bf22c9b4865a7995 1970-01-01 00:25:03.882586 -0.994  0.045   \n",
       "\n",
       "       z  timelapse                                  filename      t  \n",
       "0 -0.036      False  e2f795a7-6a7d-4500-b5d7-4569de996811.mov  000.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accel_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import heappush, heappop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def heapsort(iterable):\n",
    "    h = []\n",
    "    for value in iterable:\n",
    "        heappush(h, value)\n",
    "    return [heappop(h) for i in range(len(h))]\n",
    "\n",
    "heapsort([1, 3, 5, 7, 9, 2, 4, 6, 8, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define named tuple\n",
    "Accelerations = namedtuple('Accelerations', accel_cols)\n",
    "\n",
    "# Assign records to named tuple\n",
    "records = [Accelerations(*record) for record in accel_df.to_records(index=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accelerations(offset=0.8220608865228429, ride_id='c9a2b46c9aa515b632eddc45c4868482', uuid='19b9aa10588646b3bf22c9b4865a7995', timestamp=numpy.datetime64('1970-01-01T00:25:03.882586000'), x=-0.994, y=0.045, z=-0.036000000000000004, timelapse=False, filename='e2f795a7-6a7d-4500-b5d7-4569de996811.mov', t='000.0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = []\n",
    "for i in records:\n",
    "    heappush(h, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accelerations(offset=0.8220608865228429, ride_id='c9a2b46c9aa515b632eddc45c4868482', uuid='19b9aa10588646b3bf22c9b4865a7995', timestamp=numpy.datetime64('1970-01-01T00:25:03.882586000'), x=-0.994, y=0.045, z=-0.036000000000000004, timelapse=False, filename='e2f795a7-6a7d-4500-b5d7-4569de996811.mov', t='000.0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heappop(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accelerations(offset=0.8420608865228429, ride_id='c9a2b46c9aa515b632eddc45c4868482', uuid='19b9aa10588646b3bf22c9b4865a7995', timestamp=numpy.datetime64('1970-01-01T00:25:03.882586000'), x=-0.998, y=0.046, z=-0.04, timelapse=False, filename='e2f795a7-6a7d-4500-b5d7-4569de996811.mov', t='000.0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heappop(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accelerations(offset=0.862060886522843, ride_id='c9a2b46c9aa515b632eddc45c4868482', uuid='19b9aa10588646b3bf22c9b4865a7995', timestamp=numpy.datetime64('1970-01-01T00:25:03.882586000'), x=-0.999, y=0.047, z=-0.036000000000000004, timelapse=False, filename='e2f795a7-6a7d-4500-b5d7-4569de996811.mov', t='000.0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heappop(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.882060886522843"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heappop(h).offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seconds since epoch = 1651878285.4538746\n"
     ]
    }
   ],
   "source": [
    "seconds = time.time()\n",
    "print('seconds since epoch =', seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seconds since epoch = 1651878385.0535262\n"
     ]
    }
   ],
   "source": [
    "seconds = time.time()\n",
    "print('seconds since epoch =', seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local time: Fri May  6 23:06:25 2022\n"
     ]
    }
   ],
   "source": [
    "# seconds passed since epoch\n",
    "# seconds = 1545925769.9618232\n",
    "local_time = time.ctime(seconds)\n",
    "print(\"Local time:\", local_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is printed immediately.\n",
      "This is printed after 2.4 seconds.\n"
     ]
    }
   ],
   "source": [
    "print(\"This is printed immediately.\")\n",
    "time.sleep(2.4)\n",
    "print(\"This is printed after 2.4 seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [1, 2, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for i in t:\n",
    "    time.sleep(i)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.82206089,   0.84206089,   0.86206089, ..., 122.45512141,\n",
       "       122.46532815, 122.46989596])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_s = accel_df['offset'].unique()\n",
    "time_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8220608865228429"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = time_s[0]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23512"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(accel_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23512"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(time_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offset</th>\n",
       "      <th>ride_id</th>\n",
       "      <th>uuid</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>timelapse</th>\n",
       "      <th>filename</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.822061</td>\n",
       "      <td>c9a2b46c9aa515b632eddc45c4868482</td>\n",
       "      <td>19b9aa10588646b3bf22c9b4865a7995</td>\n",
       "      <td>1970-01-01 00:25:03.882586</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>0.045</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>False</td>\n",
       "      <td>e2f795a7-6a7d-4500-b5d7-4569de996811.mov</td>\n",
       "      <td>000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     offset                           ride_id  \\\n",
       "0  0.822061  c9a2b46c9aa515b632eddc45c4868482   \n",
       "\n",
       "                               uuid                  timestamp      x      y  \\\n",
       "0  19b9aa10588646b3bf22c9b4865a7995 1970-01-01 00:25:03.882586 -0.994  0.045   \n",
       "\n",
       "       z  timelapse                                  filename      t  \n",
       "0 -0.036      False  e2f795a7-6a7d-4500-b5d7-4569de996811.mov  000.0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accel_df[accel_df['offset'] == test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "##NOPE\n",
    "# time_start = time.time()\n",
    "# for i in t:\n",
    "#     if (time.time()-time_start) == i:\n",
    "#         print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##YEP\n",
    "# import time\n",
    "\n",
    "# test = [1, 1, 4, 5, 8]\n",
    "# time_start = time.time()\n",
    "# for i in test:\n",
    "#     while (time.time() - time_start < i):\n",
    "#         pass\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading as th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "def sctn():  \n",
    "   print(\"test\")  \n",
    "S = th.Timer(1.0, sctn)  \n",
    "S.start()  \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_once: 00:05:36\n",
      "Waiting.....\n",
      "Threading started\n",
      "Repeating 00:05:36\n",
      " \n",
      "Repeating 00:05:36\n",
      " \n",
      "Repeating 00:05:36\n",
      " \n",
      "Repeating 00:05:36\n",
      " \n",
      "Repeating 00:05:36\n",
      " \n",
      "Repeating 00:05:36\n",
      " \n",
      "Repeating 00:05:36\n",
      " \n",
      "Repeating 00:05:36\n",
      " \n",
      "Repeating 00:05:36\n",
      " \n",
      "Repeating 00:05:36\n",
      " \n",
      "Repeating 00:05:36\n",
      " \n",
      "Repeating 00:05:36\n",
      " \n",
      "Repeating 00:05:37\n",
      " \n",
      "Repeating 00:05:37\n",
      " \n",
      "Repeating 00:05:37\n",
      " \n",
      "Repeating 00:05:37\n",
      " \n",
      "Repeating 00:05:37\n",
      " \n",
      "Repeating 00:05:37\n",
      " \n",
      "Repeating 00:05:37\n",
      " \n",
      "Repeating 00:05:37\n",
      " \n",
      "Repeating 00:05:37\n",
      " \n",
      "Repeating 00:05:37\n",
      " \n",
      "Repeating 00:05:37\n",
      " \n",
      "Repeating 00:05:37\n",
      " \n",
      "Repeating 00:05:37\n",
      " \n",
      "Repeating 00:05:37\n",
      " \n",
      "Repeating 00:05:37\n",
      " \n",
      "Repeating 00:05:37\n",
      " \n",
      "Repeating 00:05:37\n",
      " \n",
      "Repeating 00:05:37\n",
      " \n",
      "Repeating 00:05:37\n",
      " \n",
      "Repeating 00:05:37\n",
      " \n",
      "Repeating 00:05:37\n",
      " \n",
      "Repeating 00:05:37\n",
      " \n",
      "Repeating 00:05:37\n",
      " \n",
      "Repeating 00:05:37\n",
      " \n",
      "Repeating 00:05:37\n",
      " \n",
      "Repeating 00:05:37\n",
      " \n",
      "Repeating 00:05:37\n",
      " \n",
      "Repeating 00:05:37\n",
      " \n",
      "Repeating 00:05:37\n",
      " \n",
      "Repeating 00:05:37\n",
      " \n",
      "Repeating 00:05:37\n",
      " \n",
      "Repeating 00:05:37\n",
      " \n",
      "Repeating 00:05:37\n",
      " \n",
      "Repeating 00:05:37\n",
      " \n",
      "Repeating 00:05:37\n",
      " \n",
      "Repeating 00:05:37\n",
      " \n",
      "Repeating 00:05:37\n",
      " \n",
      "Timeout: 00:05:37\n",
      "Threading finishing\n"
     ]
    }
   ],
   "source": [
    "##Timers  \n",
    "##Execute code at timed intervals  \n",
    "##Imports and Displays  \n",
    "import time  \n",
    "from threading import Timer  \n",
    "def display(msg):  \n",
    "    print(msg + ' ' + time.strftime('%H:%M:%S'))  \n",
    "  \n",
    "##Basic timer  \n",
    "def run_once():  \n",
    "    display('run_once:')  \n",
    "    t=Timer(1,display,['Timeout:'])  \n",
    "    t.start()#Here run is called  \n",
    "run_once()  \n",
    "##Runs immediately and once  \n",
    "print('Waiting.....')  \n",
    "  \n",
    "##Lets make our timer run in intervals  \n",
    "##Put it into a class  \n",
    "##Making it run until we stop it  \n",
    "##Just getting crazy.Notice We have multiple timers at once!  \n",
    "class RepeatTimer(Timer):  \n",
    "    def run(self):  \n",
    "        while not self.finished.wait(self.interval):  \n",
    "            self.function(*self.args,**self.kwargs)  \n",
    "            print(' ')  \n",
    "##We are now creating a thread timer and controling it  \n",
    "timer = RepeatTimer(.02,display,['Repeating'])  \n",
    "timer.start() #recalling run  \n",
    "print('Threading started')  \n",
    "time.sleep(1)#It gets suspended for the given number of seconds  \n",
    "print('Threading finishing')  \n",
    "timer.cancel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.020000000000000018"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accel_df.offset[1] - accel_df.offset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.020000000000000018"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accel_df.offset[2] - accel_df.offset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01999999999999602"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accel_df.offset[23502] - accel_df.offset[23501]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23512"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(accel_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005173182456561101"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(accel_df.offset[23511] - accel_df.offset[0]) / len(accel_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23512, 10)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accel_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "offset                                       0.822061\n",
       "ride_id              c9a2b46c9aa515b632eddc45c4868482\n",
       "uuid                 19b9aa10588646b3bf22c9b4865a7995\n",
       "timestamp                  1970-01-01 00:25:03.882586\n",
       "x                                              -0.994\n",
       "y                                               0.045\n",
       "z                                              -0.036\n",
       "timelapse                                       False\n",
       "filename     e2f795a7-6a7d-4500-b5d7-4569de996811.mov\n",
       "t                                               000.0\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accel_df.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'offset': 0.8220608865228429,\n",
       " 'ride_id': 'c9a2b46c9aa515b632eddc45c4868482',\n",
       " 'uuid': '19b9aa10588646b3bf22c9b4865a7995',\n",
       " 'timestamp': Timestamp('1970-01-01 00:25:03.882586'),\n",
       " 'x': -0.994,\n",
       " 'y': 0.045,\n",
       " 'z': -0.036000000000000004,\n",
       " 'timelapse': False,\n",
       " 'filename': 'e2f795a7-6a7d-4500-b5d7-4569de996811.mov',\n",
       " 't': '000.0'}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = accel_df.loc[0].to_dict()\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8220608865228429"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['offset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 2, 3]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "for i in t:\n",
    "    while (time.time() - time_start) < i:\n",
    "        pass\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load location data into pandas dataframe\n",
    "locat_df = pq.ParquetDataset(\n",
    "    src_data_path + 'locations/').read_pandas().to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns\n",
    "locat_cols = [\n",
    "    'offset',\n",
    "    'id', \n",
    "    'ride_id', \n",
    "    'uuid', \n",
    "    'timestamp', \n",
    "    'course', \n",
    "    'latitude',\n",
    "    'longitude', \n",
    "    'geohash', \n",
    "    'speed', \n",
    "    'accuracy', \n",
    "    'timelapse', \n",
    "    'filename',\n",
    "    't'\n",
    "]\n",
    "\n",
    "# Order df by specified columns & sort by offset value\n",
    "locat_df = locat_df[locat_cols].sort_values(by=['offset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.525060886522843"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locat_df.offset[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.077912529556645"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locat_df.offset.iloc[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offset</th>\n",
       "      <th>id</th>\n",
       "      <th>ride_id</th>\n",
       "      <th>uuid</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>course</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>geohash</th>\n",
       "      <th>speed</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>timelapse</th>\n",
       "      <th>filename</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.077913</td>\n",
       "      <td>85c61911b7fe2ced1000c33c9e932706</td>\n",
       "      <td>6760ffa3f41908695d1405b776c3e8d5</td>\n",
       "      <td>dad7eae44e784b549c8c5a3aa051a8c7</td>\n",
       "      <td>1970-01-01 00:25:07.320453</td>\n",
       "      <td>158.203125</td>\n",
       "      <td>40.677641</td>\n",
       "      <td>-73.817930</td>\n",
       "      <td>dr5x2jpkmtcy</td>\n",
       "      <td>2.12</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>d745b92f-aefd-467d-9121-7a71308e8d6d.mov</td>\n",
       "      <td>000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.525061</td>\n",
       "      <td>58682c5d48cad9d9e103431d773615bf</td>\n",
       "      <td>c9a2b46c9aa515b632eddc45c4868482</td>\n",
       "      <td>19b9aa10588646b3bf22c9b4865a7995</td>\n",
       "      <td>1970-01-01 00:25:03.882586</td>\n",
       "      <td>299.619141</td>\n",
       "      <td>40.762870</td>\n",
       "      <td>-73.961949</td>\n",
       "      <td>dr5ruuwscttz</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>e2f795a7-6a7d-4500-b5d7-4569de996811.mov</td>\n",
       "      <td>000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.525061</td>\n",
       "      <td>58682c5d48cad9d9e103431d773615bf</td>\n",
       "      <td>c9a2b46c9aa515b632eddc45c4868482</td>\n",
       "      <td>19b9aa10588646b3bf22c9b4865a7995</td>\n",
       "      <td>1970-01-01 00:25:03.882583</td>\n",
       "      <td>299.619141</td>\n",
       "      <td>40.762870</td>\n",
       "      <td>-73.961949</td>\n",
       "      <td>dr5ruuwsctv3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>e2f795a7-6a7d-4500-b5d7-4569de996811.mov</td>\n",
       "      <td>004.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.077913</td>\n",
       "      <td>85c61911b7fe2ced1000c33c9e932706</td>\n",
       "      <td>6760ffa3f41908695d1405b776c3e8d5</td>\n",
       "      <td>dad7eae44e784b549c8c5a3aa051a8c7</td>\n",
       "      <td>1970-01-01 00:25:07.320449</td>\n",
       "      <td>159.960938</td>\n",
       "      <td>40.677883</td>\n",
       "      <td>-73.818047</td>\n",
       "      <td>dr5x2jpmfffw</td>\n",
       "      <td>11.75</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>d745b92f-aefd-467d-9121-7a71308e8d6d.mov</td>\n",
       "      <td>004.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.077913</td>\n",
       "      <td>85c61911b7fe2ced1000c33c9e932706</td>\n",
       "      <td>6760ffa3f41908695d1405b776c3e8d5</td>\n",
       "      <td>dad7eae44e784b549c8c5a3aa051a8c7</td>\n",
       "      <td>1970-01-01 00:25:07.320446</td>\n",
       "      <td>159.609375</td>\n",
       "      <td>40.678191</td>\n",
       "      <td>-73.818193</td>\n",
       "      <td>dr5x2jppxkqj</td>\n",
       "      <td>13.15</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>d745b92f-aefd-467d-9121-7a71308e8d6d.mov</td>\n",
       "      <td>007.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     offset                                id  \\\n",
       "1  1.077913  85c61911b7fe2ced1000c33c9e932706   \n",
       "0  1.525061  58682c5d48cad9d9e103431d773615bf   \n",
       "2  4.525061  58682c5d48cad9d9e103431d773615bf   \n",
       "3  5.077913  85c61911b7fe2ced1000c33c9e932706   \n",
       "5  8.077913  85c61911b7fe2ced1000c33c9e932706   \n",
       "\n",
       "                            ride_id                              uuid  \\\n",
       "1  6760ffa3f41908695d1405b776c3e8d5  dad7eae44e784b549c8c5a3aa051a8c7   \n",
       "0  c9a2b46c9aa515b632eddc45c4868482  19b9aa10588646b3bf22c9b4865a7995   \n",
       "2  c9a2b46c9aa515b632eddc45c4868482  19b9aa10588646b3bf22c9b4865a7995   \n",
       "3  6760ffa3f41908695d1405b776c3e8d5  dad7eae44e784b549c8c5a3aa051a8c7   \n",
       "5  6760ffa3f41908695d1405b776c3e8d5  dad7eae44e784b549c8c5a3aa051a8c7   \n",
       "\n",
       "                   timestamp      course   latitude  longitude       geohash  \\\n",
       "1 1970-01-01 00:25:07.320453  158.203125  40.677641 -73.817930  dr5x2jpkmtcy   \n",
       "0 1970-01-01 00:25:03.882586  299.619141  40.762870 -73.961949  dr5ruuwscttz   \n",
       "2 1970-01-01 00:25:03.882583  299.619141  40.762870 -73.961949  dr5ruuwsctv3   \n",
       "3 1970-01-01 00:25:07.320449  159.960938  40.677883 -73.818047  dr5x2jpmfffw   \n",
       "5 1970-01-01 00:25:07.320446  159.609375  40.678191 -73.818193  dr5x2jppxkqj   \n",
       "\n",
       "   speed  accuracy  timelapse                                  filename      t  \n",
       "1   2.12      10.0      False  d745b92f-aefd-467d-9121-7a71308e8d6d.mov  000.0  \n",
       "0   0.00      10.0      False  e2f795a7-6a7d-4500-b5d7-4569de996811.mov  000.0  \n",
       "2   0.00      10.0      False  e2f795a7-6a7d-4500-b5d7-4569de996811.mov  004.5  \n",
       "3  11.75      10.0      False  d745b92f-aefd-467d-9121-7a71308e8d6d.mov  004.5  \n",
       "5  13.15      10.0      False  d745b92f-aefd-467d-9121-7a71308e8d6d.mov  007.8  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = locat_df.head()\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(test)):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.077912529556645"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['offset'].iloc[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0779125295566454\n",
      "1.525060886522843\n",
      "4.5250608865228426\n",
      "5.077912529556645\n",
      "8.077912529556645\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "for i in range(len(test)):\n",
    "    j = test['offset'].iloc[i]\n",
    "    while (time.time() - time_start) < j:\n",
    "        pass\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'offset': 0.8220608865228429,\n",
       " 'ride_id': 'c9a2b46c9aa515b632eddc45c4868482',\n",
       " 'uuid': '19b9aa10588646b3bf22c9b4865a7995',\n",
       " 'timestamp': Timestamp('1970-01-01 00:25:03.882586'),\n",
       " 'x': -0.994,\n",
       " 'y': 0.045,\n",
       " 'z': -0.036000000000000004,\n",
       " 'timelapse': False,\n",
       " 'filename': 'e2f795a7-6a7d-4500-b5d7-4569de996811.mov',\n",
       " 't': '000.0'}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = accel_df.loc[0].to_dict()\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic \"DoeJohn-locations\" already exists\n"
     ]
    }
   ],
   "source": [
    "def create_kafka_topic(topic_name, config=config, num_partitions=1, replication_factor=1):\n",
    "    bootstrap_servers = config['bootstrap_servers']\n",
    "    client_id = config['client_id']\n",
    "    topic_prefix = config['topic_prefix']\n",
    "    name = '{}-{}'.format(topic_prefix, topic_name)\n",
    "    \n",
    "    admin_client = KafkaAdminClient(\n",
    "        bootstrap_servers=bootstrap_servers, \n",
    "        client_id=client_id\n",
    "    )\n",
    "    \n",
    "    topic = NewTopic(\n",
    "        name=name,\n",
    "        num_partitions=num_partitions,\n",
    "        replication_factor=replication_factor\n",
    "    )\n",
    "\n",
    "    topic_list = [topic]\n",
    "    try:\n",
    "        admin_client.create_topics(new_topics=topic_list)\n",
    "        print('Created topic \"{}\"'.format(name))\n",
    "    except TopicAlreadyExistsError as e:\n",
    "        print('Topic \"{}\" already exists'.format(name))\n",
    "    \n",
    "create_kafka_topic('locations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kafka Producer\n",
    "\n",
    "The following code creates a `KafkaProducer` object which you can use to send Python objects that are serialized as JSON.\n",
    "\n",
    "**Note:** This producer serializes Python objects as JSON. This means that object must be JSON serializable.  As an example, Python `DateTime` values are not JSON serializable and must be converted to a string (e.g. ISO 8601) or a numeric value (e.g. a Unix timestamp) before being sent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer = KafkaProducer(\n",
    "  bootstrap_servers=config['bootstrap_servers'],\n",
    "  value_serializer=lambda x: json.dumps(x).encode('utf-8')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send Data Function\n",
    "\n",
    "The `send_data` function sends a Python object to a Kafka topic. This function adds the `topic_prefix` to the topic so `send_data('locations', data)` sends a JSON serialized message to `DoeJohn-locations`. The function also registers callbacks to let you know if the message has been sent or if an error has occured. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_send_success(record_metadata):\n",
    "    print('Message sent:\\n    Topic: \"{}\"\\n    Partition: {}\\n    Offset: {}'.format(\n",
    "        record_metadata.topic,\n",
    "        record_metadata.partition,\n",
    "        record_metadata.offset\n",
    "    ))\n",
    "    \n",
    "def on_send_error(excp):\n",
    "    print('I am an errback', exc_info=excp)\n",
    "    # handle exception\n",
    "\n",
    "def send_data(topic, data, config=config, producer=producer, msg_key=None):\n",
    "    topic_prefix = config['topic_prefix']\n",
    "    topic_name = '{}-{}'.format(topic_prefix, topic)\n",
    "    \n",
    "    if msg_key is not None:\n",
    "        key = msg_key\n",
    "    else:\n",
    "        key = uuid.uuid4().hex\n",
    "    \n",
    "    producer.send(\n",
    "        topic_name, \n",
    "        value=data,\n",
    "        key=key.encode('utf-8')\n",
    "    ).add_callback(on_send_success).add_errback(on_send_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message sent:\n",
      "    Topic: \"DoeJohn-locations\"\n",
      "    Partition: 0\n",
      "    Offset: 1467\n"
     ]
    }
   ],
   "source": [
    "example_data = dict(\n",
    "    key1='value1',\n",
    "    key2='value2'\n",
    ")\n",
    "\n",
    "send_data('locations', example_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
